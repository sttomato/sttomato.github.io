<?xml version="1.0" encoding="utf-8"?>
<search>
  
    
    <entry>
      <title><![CDATA[LeetCode Backtracking]]></title>
      <url>%2F2017%2F09%2F21%2FLeetCode-Backtracking%2F</url>
      <content type="text"><![CDATA[LeetCode BacktrackingProblems Lists What is Backtracking? 357. Count Numbers with Unique DigitsDescriptionGiven a non-negative integer n, count all numbers with unique digits, x, where $0 \le x &lt; 10^n$. Example:Given n = 2, return 91. (The answer should be the total numbers in the range of $0 \le x &lt; 100$, excluding [11,22,33,44,55,66,77,88,99]) Credits:Special thanks to @memoryless for adding this problem and creating all test cases. 解题思路：一个n位数并且每位数字不重复，总共有这么多个数字 f(n) = {A_{10}^n} - {A_{9}}^{n-1}设 f(0) = A_{10}^0 = 1然后累加。 1234567891011121314151617181920212223class Solution &#123;public: int countNumbersWithUniqueDigits(int n) &#123; if (n &lt; 0) return 0; if (n &gt; 10) n = 10; int result = 0; int tmp1 = 1; int tmp2 = 0; for (int i = 0; i &lt;= n; i++) &#123; result += tmp1 - tmp2; tmp1 *= 10 - i; if (i == 0) &#123; tmp2 = 1; &#125; else &#123; tmp2 *= 10 - i; &#125; &#125; return result; &#125;&#125;; 回溯方法 1234567891011121314151617181920212223242526class Solution &#123;public: int countNumbersWithUniqueDigits(int n) &#123; int res = 1, max = pow(10, n), used = 0; for (int i = 1; i &lt; 10; ++i) &#123; used |= (1 &lt;&lt; i); res += search(i, max, used); used &amp;= ~(1 &lt;&lt; i); &#125; return res; &#125; int search(int pre, int max, int used) &#123; int res = 0; if (pre &lt; max) ++res; else return res; for (int i = 0; i &lt; 10; ++i) &#123; if (!(used &amp; (1 &lt;&lt; i))) &#123; used |= (1 &lt;&lt; i); int cur = 10 * pre + i; res += search(cur, max, used); used &amp;= ~(1 &lt;&lt; i); &#125; &#125; return res; &#125;&#125;; bug版回溯123456789101112131415161718192021222324252627282930313233class Solution &#123;public: int countNumbersWithUniqueDigits(int n) &#123; if (n &gt; 10) &#123; return countNumbersWithUniqueDigits(10); &#125; vector&lt;bool&gt; used(10, false); int count = 1; long max = pow(10, n); for (int i = 0; i &lt; 10; i++) &#123; used[i] = true; count += search(i, max, used); used[i] = false; &#125; return count; &#125; int search(long pre, long max, vector&lt;bool&gt;&amp; used) &#123; int count = 0; if (pre &lt; max) count++; else return count; for (int i = 0; i &lt; 10; i++) &#123; if (!used[i]) &#123; used[i] = true; long cur = 10 * pre + i; count += search(cur, max, used); used[i] = false; &#125; &#125; return count; &#125;&#125;; 22. Generate ParenthesesDescriptionGiven n pairs of parentheses, write a function to generate all combinations of well-formed parentheses. For example, given n = 3, a solution set is:1234567[ "((()))", "(()())", "(())()", "()(())", "()()()"] 解题思路：合法字符串的任意位置，右括号数量不大于左括号数量。12345678910111213141516class Solution &#123;public: vector&lt;string&gt; generateParenthesis(int n) &#123; vector&lt;string&gt; res; func(n, n, "", res); return res; &#125; void func(int left, int right, string tmp, vector&lt;string&gt; &amp;res) &#123; if (left &gt; right) return; if (left ==0 &amp;&amp; right == 0) res.push_back(tmp); if (left &gt; 0) func(left - 1, right, tmp + '(', res); if (right &gt; 0) func(left, right - 1, tmp + ')', res); &#125;&#125;; 参考来源 216. Combination Sum IIIDescription： Find all possible combinations of k numbers that add up to a number n, given that only numbers from 1 to 9 can be used and each combination should be a unique set of numbers. Example 1: Input: k = 3, n = 7 Output:1[[1,2,4]] Example 2: Input: k = 3, n = 9 Output:1[[1,2,6], [1,3,5], [2,3,4]] Credits:Special thanks to @mithmatt for adding this problem and creating all test cases. 解题思路：把已经算过的数放入一个向量中，在不满足条件的情况下，把值退出来；满足条件下，把最终结果保存 12345678910111213141516171819class Solution &#123;public: vector&lt;vector&lt;int&gt;&gt; combinationSum3(int k, int n) &#123; vector&lt;vector&lt;int&gt;&gt; res; vector&lt;int&gt; tmp; func(k, n, 1, tmp, res); return res; &#125; void func(int k, int n, int level, vector&lt;int&gt; &amp;tmp, vector&lt;vector&lt;int&gt;&gt; &amp;res) &#123; if (n &lt; 0) return; if (n == 0 &amp;&amp; tmp.size() == k) res.push_back(tmp); for (int i = level; i &lt;= 9; i++) &#123; tmp.push_back(i); func(k, n - i, i + 1, tmp, res); //func(k, n - i, level + 1, tmp, res);//bug版本；也能输出，但是会出现重复数字 tmp.pop_back(); &#125; &#125;&#125;; 参考 46. PermutationsDescription： Given a collection of distinct numbers, return all possible permutations. For example,[1,2,3] have the following permutations:12345678[ [1,2,3], [1,3,2], [2,1,3], [2,3,1], [3,1,2], [3,2,1]] ！！！这是宝宝写出来的第一个回溯算法题！！！解题思路：大循环【从nums中擦除一个数，在tmp中加入，然后把nums和tmp放到下一层递归；终止条件是当nums==0，tmp的大小和最初nums一样大时，查找tmp是否在结果中，如果在跳出，否则加入结果；然后把擦除的数插入回nums，tmp弹出这个数】123456789101112131415161718192021class Solution &#123;public: vector&lt;vector&lt;int&gt;&gt; permute(vector&lt;int&gt;&amp; nums) &#123; vector&lt;vector&lt;int&gt;&gt; res; vector&lt;int&gt; tmp; func(nums, tmp, res); return res; &#125; void func(vector&lt;int&gt;&amp; nums, vector&lt;int&gt;&amp; tmp, vector&lt;vector&lt;int&gt;&gt;&amp; res) &#123; if (nums.size() == 0 &amp;&amp; find(res.begin(), res.end(), tmp) != res.end()) return; if (nums.size() == 0 &amp;&amp; find(res.begin(), res.end(), tmp) == res.end()) res.push_back(tmp); for (auto iter = nums.begin(); iter != nums.end(); iter++) &#123; int val = *iter; tmp.push_back(val); nums.erase(iter); func(nums, tmp, res); nums.insert(iter, val); tmp.pop_back(); &#125; &#125;&#125;; 别人的解 89. Gray CodeDescription: The gray code is a binary numeral system where two successive values differ in only one bit. Given a non-negative integer n representing the total number of bits in the code, print the sequence of gray code. A gray code sequence must begin with 0. For example, given n = 2, return $[0,1,3,2]$. Its gray code sequence is:123400 - 001 - 111 - 310 - 2 Note:For a given n, a gray code sequence is not uniquely defined. For example, $[0,2,3,1]$ is also a valid gray code sequence according to the above definition. For now, the judge is able to judge based on one instance of gray code sequence. Sorry about that. 公式法：每个格雷码 = 当前二进制数 异或 （当前二进制数右移一位） 12345678910class Solution &#123;public: vector&lt;int&gt; grayCode(int n) &#123; vector&lt;int&gt; res; for (int i = 0; i &lt; pow(2, n); i++) &#123; res.push_back((i &gt;&gt; 1) ^ i); &#125; return res; &#125;&#125;; 镜像翻转法： 12345678910111213class Solution &#123;public: vector&lt;int&gt; grayCode(int n) &#123; vector&lt;int&gt; res; res.push_back(0); for (int i = 0; i &lt; n; i++) &#123; for (int j = pow(2, i) - 1; j &gt;= 0; j--) &#123; res.push_back(res[j] | (1 &lt;&lt; i)); &#125; &#125; return res; &#125;&#125;; 回溯法，目前没搞明白……囧 回溯法1 1234567891011121314151617181920212223class Solution &#123;public: vector&lt;int&gt; grayCode(int n) &#123; vector&lt;int&gt; res; unordered_set&lt;int&gt; s; helper(n, s, 0, res); return res; &#125; void helper(int n, unordered_set&lt;int&gt;&amp; s, int out, vector&lt;int&gt;&amp; res) &#123; if (!s.count(out)) &#123; s.insert(out); res.push_back(out); &#125; for (int i = 0; i &lt; n; ++i) &#123; int t = out; if ((t &amp; (1 &lt;&lt; i)) == 0) t |= (1 &lt;&lt; i); else t &amp;= ~(1 &lt;&lt; i); if (s.count(t)) continue; helper(n, s, t, res); break; &#125; &#125;&#125;; 回溯法21234567891011121314151617181920212223242526272829303132333435int conversion(int n)&#123; int temp=1; if(n==1) return 1; for(int i=1;i&lt;n;i++) temp=temp*2; return temp;&#125;vector&lt;int&gt; grayCode(int n) &#123; vector&lt;int&gt; result; if(n==0) &#123; result.push_back(0); return result; &#125; if(n==1) &#123; result.push_back(0); result.push_back(1); return result; &#125; else &#123; //queue&lt;int&gt; temp; result=grayCode(n-1); int len=result.size(); for(int i=len-1;i&gt;=0;--i) &#123; int temp=result[i]+conversion(n); result.push_back(temp); &#125; return result; &#125;&#125; SubsetsDescription： Given a set of distinct integers, nums, return all possible subsets. Note: The solution set must not contain duplicate subsets. For example,If nums = $[1,2,3]$, a solution is:12345678910[ [3], [1], [2], [1,2,3], [1,3], [2,3], [1,2], []] 解题思路：12345678910 [] / \ / \ / \ [1] [] / \ / \ / \ / \ [1 2] [1] [2] [] / \ / \ / \ / \[1 2 3] [1 2] [1 3] [1] [2 3] [2] [3] [] 1234567891011121314151617class Solution &#123;public: vector&lt;vector&lt;int&gt;&gt; subsets(vector&lt;int&gt;&amp; nums) &#123; vector&lt;vector&lt;int&gt;&gt; res; vector&lt;int&gt; tmp = &#123;&#125;; func(0, tmp, res, nums); return res; &#125; void func(int pos, vector&lt;int&gt; &amp;tmp, vector&lt;vector&lt;int&gt;&gt; &amp;res, vector&lt;int&gt; &amp;nums) &#123; res.push_back(tmp); for (int i = pos; i &lt; nums.size(); i ++) &#123; tmp.push_back(nums[i]); func(i + 1, tmp, res, nums); tmp.pop_back(); &#125; &#125;&#125;; 77. CombinationsDescription:Given two integers n and k, return all possible combinations of k numbers out of 1 … n. For example,If n = 4 and k = 2, a solution is:12345678[ [2,4], [3,4], [2,3], [1,2], [1,3], [1,4],] 解题思路：这题是组合情况，比之前的46题排列情况更简单一点 123456789101112131415161718192021222324class Solution &#123;public: vector&lt;vector&lt;int&gt;&gt; combine(int n, int k) &#123; vector&lt;vector&lt;int&gt;&gt; res; vector&lt;int&gt; input; vector&lt;int&gt; tmp; for (int i = 1; i &lt;= n; i++) &#123; input.push_back(i); &#125; func(n, k, tmp, 0, res); return res; &#125; void func(int n, int k, vector&lt;int&gt; &amp;tmp, int pos, vector&lt;vector&lt;int&gt;&gt; &amp;res) &#123; if (tmp.size() == k &amp;&amp; find(res.begin(), res.end(), tmp) == res.end()) res.push_back(tmp); else if (tmp.size() == k) return; for (int i = pos; i &lt; n; i++) &#123; tmp.push_back(i + 1); func(n, k, tmp, i + 1, res); tmp.pop_back(); &#125; &#125;&#125;;]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[2017秋招——京东]]></title>
      <url>%2F2017%2F09%2F16%2F2017%E7%A7%8B%E6%8B%9B%E7%AC%AC%E4%B8%80%E5%9C%BA%EF%BC%9A%E4%BA%AC%E4%B8%9C%2F</url>
      <content type="text"><![CDATA[大量数据结构的问题 查找方式有哪些，都有哪些区别； 数组和链表的区别，分别是怎么实现的； 哈希表是如何实现的； 如何实现平衡树； 介绍一下红黑树；博客1，博客2 如何实现树的遍历； 汉诺塔问题 深度学习方面 过拟合、欠拟合； 过拟合有哪些解决方法； 欠拟合有哪些解决方法； GoogleNet； 怎么样去检测图像中的汽车； 深度学习有哪些超参数 哈希 构造合适的散列函数 除余法除数选用较大的素数，降低冲突发生的可能 MAD法 非递归版本先序遍历12345678910111213141516void PreOrder(TreeNode* root) &#123; stack&lt;TreeNode*&gt; s; TreeNode* p = root; while (p != NULL || !s.empty()) &#123; if (P != NULL) &#123; s.push(p); cout &lt;&lt; p -&gt; val &lt;&lt; endl; p = p -&gt; left; &#125; else &#123; p = s.top(); s.pop(); p = p -&gt; right; &#125; &#125;&#125; 中序遍历12345678910111213141516void InOrder(TreeNode* root) &#123; stack&lt;TreeNode*&gt; s; TreeNode* p = root; while (p != NULL || !s.empty()) &#123; if (P != NULL) &#123; s.push(p); p = p -&gt; left; &#125; else &#123; p = s.top(); s.pop(); cout &lt;&lt; p -&gt; val &lt;&lt; endl; p = p -&gt; right; &#125; &#125; &#125; 后序遍历 123456789101112131415161718192021void PostOrder(TreeNode* root) &#123;void InOrder(TreeNode* root) &#123; stack&lt;TreeNode*&gt; s; TreeNode* p = root; while (p != NULL || !s.empty()) &#123; if (P != NULL) &#123; s.push(p); p = p -&gt; left; &#125; else &#123; p = s.top(); s.pop(); if (! p -&gt; right) &#123; cout &lt;&lt; p -&gt; val &lt;&lt; endl; &#125; p = p -&gt; right; &#125; &#125; &#125; &#125;]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[降维之PCA主成分分析原理]]></title>
      <url>%2F2017%2F09%2F15%2F%E9%99%8D%E7%BB%B4%E4%B9%8BPCA%E4%B8%BB%E6%88%90%E5%88%86%E5%88%86%E6%9E%90%E5%8E%9F%E7%90%86%2F</url>
      <content type="text"><![CDATA[背景在许多领域的研究与应用中，往往需要对反映事物的多个变量进行大量的观测，收集大量数据以便进行分析寻找规律。多变量大样本无疑会为研究和应用提供了丰富的信息，但也在一定程度上增加了数据采集的工作量，更重要的是在多数情况下，许多变量之间可能存在相关性，从而增加了问题分析的复杂性，同时对分析带来不便。如果分别对每个指标进行分析，分析往往是孤立的，而不是综合的。盲目减少指标会损失很多信息，容易产生错误的结论。 因此需要找到一个合理的方法，在减少需要分析的指标同时，尽量减少原指标包含信息的损失，以达到对所收集数据进行全面分析的目的。由于各变量间存在一定的相关关系，因此有可能用较少的综合指标分别综合存在于各变量中的各类信息。主成分分析与因子分析就属于这类降维的方法。 目的PCA（Principal Component Analysis）是一种常用的数据分析方法。PCA通过线性变换将原始数据变换为一组各维度线性无关的表示，可用于提取数据的主要特征分量，常用于高维数据的降维。能够对高维数据降维的算法包括： LASSO 主成分分析法 聚类分析 小波分析法 线性判别法 拉普拉斯特征映射 作用降维有什么作用呢？ 数据在低维下更容易处理、更容易使用； 相关特征，特别是重要特征更能在数据中明确的显示出来；如果只有两维或者三维的话，更便于可视化展示； 去除数据噪声 降低算法开销 常见的降维算法有主成分分析（principal component analysis,PCA）、因子分析（Factor Analysis）和独立成分分析（Independent Component Analysis，ICA）。 优化目标将一组N维向量降为K维（K大于0，小于N），其目标是选择K个单位（模为1）正交基，使得原始数据变换到这组基上后，各字段两两间协方差为0，而字段的方差则尽可能大（在正交的约束下，取最大的K个方差） 注意：PCA的变换矩阵是协方差矩阵，K-L变换的变换矩阵可以有很多种（二阶矩阵、协方差矩阵、总类内离散度矩阵等等）。当K-L变换矩阵为协方差矩阵时，等同于PCA。 原理最大化样本点在基上的投影，使得数据点尽量的分离。令第一主成分的方向是$u_1$，我们的目标就是将样本点在该方向上的投影最大化，即： \max {\frac{1}{n} \sum_{i=1}^n < u_1,x_i >^2} \frac{1}{n}\sum_{i=1}^n < u_1, x_i > \rightarrow \frac{1}{n}\sum_{i=1}^n(x_1^Tu_1)^2=\frac{1}{n}\sum_{i=1}^n(x_1^Tu_1)^T(x_1^Tu_1) =\frac{1}{n} \sum_{i=1}^n(u_1^T x_1 x_1^T u_1)= \frac{1}{n}u_1^T \left( \sum_{i=1}^n x_1 x_1^T \right) u_1 = \frac{1}{n} u_1^T \left(XX^T \right) u_1其中的$X=[x_1,x_2,…,x_n]^T,x_i\in R^{m}$。那么优化函数就变成了： \max u_1^T\left(XX^T\right)u_1以上式子是个二次型，可以证明XX^T是半正定矩阵，所以上式必然有最大值。 \max u_1^T\left(XX^T\right)u_1=\max ||X^Tu_1||_2^2优化函数 max||Wx||_2 s.t. W^TW=I解释：==最大化方差同时最小化协方差==（PCA本质上是将方差最大的方向作为主要特征，并且在各个正交方向上将数据“离相关”）。最大化方差意味着，使得每个样本点在每个维度上与均值有很大差异，就是说非常有个性，有个性才能分辨出来；同时协方差越小的话表明样本之间的互相影响就非常小，如果协方差是0的话，表示两个字段完全独立。 寻找协方差矩阵的特征向量和特征值就等价于拟合一条能保留最大方差的直线或主成分。因为特征向量追踪到了主成分的方向，而最大方差和协方差的轴线表明了数据最容易改变的方向。根据上述推导，我们发现达到优化目标就等价于将协方差矩阵对角化：即除对角线外的其它元素化为0，并且在对角线上将特征值按大小从上到下排列。协方差矩阵作为实对称矩阵，其主要性质之一就是可以正交对角化，因此就一定可以分解为特征向量和特征值。 步骤总结一下PCA的算法步骤： 设有$m$条$n$维(字段数)数据。 将原始数据按列组成$n$行$m$列矩阵X. (行数代表字段数目，一个字段就是取每个样本的该维度的数值；列数代表样本数目) 将$X$的每一行（代表一个属性字段）进行零均值化，即减去这一行的均值 求出协方差矩阵$C=\frac{1}{m}XX^T$ 求出协方差矩阵的特征值及对应的特征向量 将特征向量按对应特征值大小从上到下按行排列成矩阵，取前k行组成矩阵P $Y=PX$即为降维到k维后的数据 去均值化的目的下面两幅图是数据做中心化（centering）前后的对比，可以看到其实就是一个平移的过程，平移后所有数据的中心是(0,0). 在做PCA的时候，我们需要找出矩阵的特征向量，也就是主成分（PC）。比如说找到的第一个特征向量是a = [1, 2]，a在坐标平面上就是从原点出发到点（1，2）的一个向量。如果没有对数据做中心化，那算出来的第一主成分的方向可能就不是一个可以“描述”（或者说“概括”）数据的方向了。还是看图比较清楚。 黑色线就是第一主成分的方向。只有中心化数据之后，计算得到的方向才能比较好的“概括”原来的数据。 限制PCA虽可以很好的解除线性相关，但是对于高阶相关性就没有办法了，对于存在高阶相关性的数据，可以考虑Kernel PCA，通过Kernel函数将非线性相关转为线性相关 参考 PCA的数学原理 K-L变换和PCA的区别 从PCA和SVD的关系拾遗 数据什么时候需要做中心化和标准化处理 主成分分析（PCA）原理详解]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Hello World]]></title>
      <url>%2F2017%2F09%2F14%2Fhello-world%2F</url>
      <content type="text"><![CDATA[Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new "My New Post" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[快速排序]]></title>
      <url>%2F2017%2F09%2F13%2F%E5%BF%AB%E6%8E%92%E7%A8%8B%E5%BA%8F%2F</url>
      <content type="text"><![CDATA[博客上的代码1 博客上的代码2 1234567891011121314151617void quickSort(vector&lt;int&gt;&amp; array, int left, int right) &#123; int i = left; int j = right; int temp = array[left]; while (i != j) &#123; while (i &lt;j &amp;&amp; temp &lt;= array[j]) j --; if (i &lt; j) array[i] = array[j]; while (i &lt; j &amp;&amp; temp &gt; array[i]) i ++; if (i &lt; j) array[j] = array[i]; &#125; array[i] = temp; quickSort(array, left, i - 1); quickSort(array, i + 1, right);&#125; 分治思想 1234567891011121314151617181920212223int partition(vector&lt;int&gt;&amp; array, int left, int right) &#123; int i = left; int j = right; int temp = array[left]; while (i != j) &#123; while (i &lt;j &amp;&amp; temp &lt;= array[j]) j --; if (i &lt; j) array[i] = array[j]; while (i &lt; j &amp;&amp; temp &gt; array[i]) i ++; if (i &lt; j) array[j] = array[i]; &#125; array[i] = temp; return i;&#125;void quickSort(vector&lt;int&gt;&amp; array, int left, int right) &#123; if (left &lt; right) &#123; int dp = partition(array, left, right); quickSort(array, left, dp - 1); quickSort(array, dp + 1, right); &#125;&#125;]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[优化算法]]></title>
      <url>%2F2017%2F08%2F13%2F%E4%BC%98%E5%8C%96%E7%AE%97%E6%B3%95%2F</url>
      <content type="text"><![CDATA[优化算法对目标函数求梯度 $\nabla_{\theta} J(\theta)$ 批量梯度下降利用所有训练数据，计算目标函数梯度，$\eta$是学习率(learning rate) \theta = \theta - \eta \cdot \nabla_{\theta} J(\theta)缺点：一次参数更新需要计算整体数据的梯度，内存消耗大，不支持模型在线更新 随机梯度下降训练中，利用一个样本$x^{(i)}$ 和标签 $y^{(i)}$进行一次参数更新 \theta = \theta - \eta \cdot \nabla J(\theta;x^{(i)};y^{(i)})优点： 速度快，支持在线学习 缺点： 高方差，目标函数值剧烈波动 随机波动，容易陷入局部极小值 mini-batch 随机下降结合前两种，在训练中，利用一个 batch 样本$x^{(i)}$ 和标签 $y^{(i)}$进行一次参数更新 \theta = \theta - \eta \cdot \nabla J(\theta;x^{(i:i+n)};y^{(i:i+n)})优点： 减小参数更新的方程，收敛更平稳 可以根据内存来控制输入 Momentum帮助SGD在相关方向上加速并抑制震荡，当前向量$vt$的更新考虑了上一个时刻向量$v{t-1}$的作用 \left\{ \begin{aligned} v_t & = &\underbrace{\gamma v_{t-1}}_{momenturm \,term} &+& \eta \cdot \nabla_{\theta} J(\theta)\\ \theta & = &\theta &-& v_t \\ \end{aligned} \right.Nesterov accelerated gradient(NAG)给momentum term引入先验 \left\{ \begin{aligned} v_t & = \gamma v_{t-1} + \eta \cdot \nabla_{\theta} J(\theta - \gamma v_{t-1})\\ \theta & = \theta - v_t \\ \end{aligned} \right.AdaGrad之前的方法对所有参数$\theta$都用了相同的学习率$\eta$，AdaGrad在时刻$t$对每个参数$\theta_i$采用了不同的学习速率$\eta$$\theta_i$在$t$时刻的梯度： g_{t,i} = \nabla_\theta J(\theta_i)SGD对在$t$时刻的参数$\theta_i$更新， \theta_{t+1, i} = \theta_{t,i} - \eta \cdot g_{t,i}AdaGrad在$t$时刻的参数$\theta_i$更新， \theta_{t+1} = \theta_t - \frac{\eta}{\sqrt{G_{t,i} + \epsilon}} \cdot g_{t,i}其中，$G_{t} \in \mathbb{R}^{d \times d}$是一个对角矩阵，对角元素$i$是每个参数$\theta_i$到t时刻为止，所有时刻梯度的平方之和，$\epsilon$为避免分母为0。进一步，写成element-wise matrix-vector multiplication形式， \theta_{t+1} = \theta_t - \frac{\eta}{\sqrt{G_{t} + \epsilon}} \odot g_{t}优点 不用人工调整学习率，默认0.01 缺点 在分母中累积梯度的平方，在训练过程中导致学习率一直在减小 需要手动设置一个全局初始学习率 更新$\theta_t$时，左右两边的单位不一致 Adadelta为缓解AdaGrad学习率单调递减问题做出的扩展。不对过去所以时刻梯度平方累积，将累积时刻限制在窗口大小为$w$的区间递归使得定义为过去所有时刻梯度平方的decaying average(?)。时刻$t$的running average $E[g^2]_t$仅仅依赖于之前average和当前的梯度$\gamma$是一个衰减系数，随着时间指数衰减，因此与当前时刻比较近的$g_t$对梯度计算更起作用 E[g^2]_t = \gamma E[g^2]_{t-1} + (1-\gamma)g^2_t将对角矩阵$G_t$替换为过去$t$时刻梯度平方的dacaying average $E[g^2]_t$ \theta_{t+1} = \theta_t - \frac{\eta}{\sqrt{E[g^2]_t + \epsilon}} \odot g_{t}RMSprop和Adadelta原理相似？？？ AdamAdaptvie Moment Estimation (Adam) 自适应学习速率计算方法。保存过去梯度平方和+momentum。 m_t=\beta_1 m_{t-1} + (1 - \beta_1) g_t\\ v_t = \beta_2 v_{t - 1} + (1 - \beta_2) g_t^2其中，$m_t$和$v_t$分别是梯度的一阶矩（均值）和二阶矩（偏方差）的估计为消除估计值的偏差，计算bias-corrected \widehat{m}_t = \frac{m_t}{1-\beta^t_1}\\ \widehat{v}_t = \frac{v_t}{1 - \beta^t_2}更新规则， \theta_{t+1} = \theta_t - \frac{\eta}{\sqrt{\widehat{v}_t + \epsilon}} \widehat{m}_t默认设置，$\beta_1 = 0.9,\beta_2=0.999,\epsilon=10^{-8}$ 【各优化算法对比-投影面】]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[机器学习修炼手册]]></title>
      <url>%2F2017%2F05%2F07%2F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%BF%AE%E7%82%BC%E6%89%8B%E5%86%8C%2F</url>
      <content type="text"><![CDATA[对机器学习的学习我开始于二年级的《数据挖掘》课，当时袁老师对数据挖掘中的常用的算法做了一些介绍，但是这仅仅是个入门教学，我并没有深入了解的其中的原理。到现在我才深刻的意识到ML的重要性，我就抽空看了一些这方面的资料，整理了这一份文档。 机器学习算法包括，监督学习(回归、分类)以及非监督学习(聚类)。 梯度下降\bbox[5px,border:2px solid red] { \theta_j:=\theta_j-\alpha\frac{\partial}{\partial \theta}J(\theta) }其中$\alpha$为学习率一般为很小的数字(0.001-0.1)，$\theta$为我们需要求解的参数，$J(\theta)$为能量函数或者为损失函数，通过上述公式可知，梯度下降是沿着损失函数梯度的反方向寻找迭代寻找最优值的过程。梯度下降容易陷入局部最极小点，所以我们要采取一定的措施来阻止这种现象的发生。 过拟合（Overfitting）如果训练样本的特征过多，我们学习的假设可能在训练集上表现地很好，但是在验证集上表现地就不尽人意 避免过拟合 减少特征的大小 正则化 在保证所有特征都保留的情况下，限制$\theta$的大小，即Small values for parameters $ \theta_0,\theta_1,\theta_2…\theta_n$ 当特征量很多时，该方式仍然表现的很好 交叉验证(Cross Validation) 正则化线性回归对于线性回归而言，其损失函数形式如下： J(\theta)=\frac{1}{2m}\sum_{i=1}^{m}\left(h_{\theta}(x^{(i)})-y^{(i)}\right)^2引入正则化之后的损失函数的形式为： J(\theta)=\frac{1}{2m}\left(\sum_{i=1}^{m}(h_{\theta}(x^{(i)})-y^{(i)})^2+\lambda\sum_{j=1}^{n}\theta_{j}^2\right)GD迭代求解参数Repeat{ \theta_0:=\theta_0-\alpha\frac{1}{m}\sum_{i=1}^{m}\left(h_{\theta}(x^{(i)})-y^{(i)}\right)x_0^{(i)} \theta_j:=\theta_j-\alpha\frac{1}{m}\left(\sum_{i=1}^{m}(h_{\theta}(x^{(i)})-y^{(i)})x_j^{(i)}+\lambda\theta_j\right)}梯度下降法的学习率$\alpha$需要提前指定，并且还要制定收敛标准。 Normal Equation \theta=\left(x^Tx+\lambda\begin{bmatrix} {0}&{0}&{\cdots}&{0}\\ {0}&{1}&{\cdots}&{0}\\ {\vdots}&{\vdots}&{\ddots}&{\vdots}\\ {0}&{0}&{\cdots}&{1}\\ \end{bmatrix}_{(n+1)(n+1)}\right)^{-1}x^Ty上式是对线性回归正则化后的矩阵解。可以证明的是当$\lambda&gt;0$时，求逆符号内部的式子总是可逆的。 逻辑回归在没有加入正则化之前，逻辑回归的损失函数的形式是这样的： J(\theta)=-\frac{1}{m}\sum_{i=1}^{m}\left(y^{(i)}\log\left(h_{\theta}(x^{(i)})\right)+(1-y^{(i)})\log\left(1-h_{\theta}(x^{(i)})\right)\right)加入正则项之后的形式为： J(\theta)=-\frac{1}{m}\sum_{i=1}^{m}\left(y^{(i)}\log\left(h_{\theta}(x^{(i)})\right)+(1-y^{(i)})\log\left(1-h_{\theta}(x^{(i)})\right)\right)+\frac{\lambda}{2m}\sum_{j=1}^{n}\theta_j^2GD迭代求解参数Repeat{ \theta_0:=\theta_0-\alpha\frac{1}{m}\sum_{i=1}^{m}\left(h_{\theta}(x^{(i)})-y^{(i)}\right)x_0^{(i)}\theta_j:=\theta_j-\alpha\frac{1}{m}\left(\sum_{i=1}^{m}(h_{\theta}(x^{(i)})-y^{(i)})x_j^{(i)}+\lambda\theta_j\right)} SVM支持向量机支持向量机又被称作最大间距（Large Margin）分类器，损失函数的形式是： J(\theta)=C\sum_{i=1}^{m}\left(y^{(i)}cost_1\left(h_{\theta}(x^{(i)})\right)+(1-y^{(i)})cost_0\left(h_{\theta}(x^{(i)})\right)\right)+\frac{1}{2}\sum_{j=1}^{n}\theta_j^2其中：$h_{\theta}(x^{(i)})=\theta^Tx^{i}$，$cost_1$以及$cost_0$的形式如下图所示： \begin{cases} \text{we want } \theta^Tx\ge1, & \text{if $y$ =1} \\[2ex] \text{we want } \theta^Tx\le-1, & \text{if $y$ =0} \end{cases}]]></content>
    </entry>

    
  
  
</search>
